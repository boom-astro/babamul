{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Babamul streaming example\n",
    "\n",
    "In this notebook we'll read from Babamul streams to fetch alerts of interest\n",
    "and save them locally,\n",
    "e.g., to use in a machine learning pipeline.\n",
    "\n",
    "Before running, be sure to copy `.env.example` to `.env` and fill in\n",
    "your Babamul Kafka credentials from https://babamul.caltech.edu/profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import os\n",
    "from datetime import UTC, datetime\n",
    "from glob import glob\n",
    "\n",
    "import dotenv\n",
    "import duckdb\n",
    "import ipywidgets as widgets\n",
    "import polars as pl\n",
    "from IPython.display import display\n",
    "\n",
    "import babamul\n",
    "from babamul import LsstAlert, ZtfAlert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load secrets from a local .env file if present\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Define some parameters\n",
    "limit = 1000\n",
    "group_id = \"example-group\"\n",
    "topics = [\"babamul.lsst.ztf-match.hosted\", \"babamul.ztf.lsst-match.hosted\"]\n",
    "topics = [\"^babamul.*\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Fetch new alerts from the streams\n",
    "\n",
    "Below we read from the stream and merge new alerts into our local cache\n",
    "in `data/alerts` so we can further process them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts = []\n",
    "\n",
    "with babamul.AlertConsumer(\n",
    "    topics=topics,\n",
    "    offset=\"latest\",\n",
    "    group_id=group_id,\n",
    "    timeout=10,\n",
    ") as consumer:\n",
    "    for n, alert in enumerate(consumer):\n",
    "        if n >= limit:\n",
    "            break\n",
    "        alerts.append(alert)\n",
    "\n",
    "# Create a Polars DataFrame of all alerts and merge them with the rest of our\n",
    "# local cache\n",
    "alerts_dir = \"data/alerts\"\n",
    "os.makedirs(alerts_dir, exist_ok=True)\n",
    "\n",
    "# Only process if we got new alerts\n",
    "parquet_glob = f\"{alerts_dir}/**/*.parquet\"\n",
    "if alerts:\n",
    "    new_df = pl.DataFrame(\n",
    "        [alert.model_dump() for alert in alerts]\n",
    "    ).with_columns(\n",
    "        pl.col(\"candidate\")\n",
    "        .struct.field(\"jd\")\n",
    "        .map_elements(\n",
    "            lambda jd: datetime.fromtimestamp(\n",
    "                (jd - 2440587.5) * 86400, tz=UTC\n",
    "            ).date(),\n",
    "            return_dtype=pl.Date,\n",
    "        )\n",
    "        .alias(\"obs_date\")\n",
    "    )\n",
    "    # Merge with existing alerts cache\n",
    "    parquet_files = glob(parquet_glob, recursive=True)\n",
    "    if parquet_files:\n",
    "        existing = pl.scan_parquet(parquet_files).collect()\n",
    "        n_existing = len(existing)\n",
    "        df_combined = pl.concat([existing, new_df], how=\"vertical_relaxed\")\n",
    "    else:\n",
    "        n_existing = 0\n",
    "        df_combined = new_df\n",
    "    df_combined.write_parquet(alerts_dir, partition_by=\"obs_date\")\n",
    "    print(\n",
    "        f\"Saved {len(df_combined)} alerts to {alerts_dir} \"\n",
    "        f\"({len(new_df)} new, {n_existing} existing)\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No new alerts received from stream\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## View alerts interactively\n",
    "\n",
    "The cell below allows us to page through the alerts of interest based on a\n",
    "SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SQL query to find candidates that are likely real astrophysical\n",
    "# transients\n",
    "sql = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('{parquet_glob}', union_by_name=true)\n",
    "    WHERE\n",
    "        candidate.drb >= 0.8\n",
    "        AND (\n",
    "            candidate.jd - COALESCE(candidate.jdstarthist, candidate.jd)\n",
    "        ) <= 30\n",
    "        AND (\n",
    "            candidate.ssdistnr IS NULL\n",
    "            OR candidate.ssdistnr >= 12\n",
    "            OR candidate.ssdistnr < 0\n",
    "        )\n",
    "        AND (properties.star IS NULL OR properties.star = FALSE)\n",
    "        AND (\n",
    "            properties.near_brightstar IS NULL\n",
    "            OR properties.near_brightstar = FALSE\n",
    "        )\n",
    "        AND (candidate.isdiffpos IS NULL OR candidate.isdiffpos = TRUE)\n",
    "        AND properties.stationary = TRUE\n",
    "    ORDER BY obs_date DESC\n",
    "\"\"\"\n",
    "\n",
    "relevant_alerts = duckdb.sql(sql).pl()\n",
    "\n",
    "\n",
    "def row_to_alert(row: dict) -> ZtfAlert | LsstAlert:\n",
    "    \"\"\"Convert a Polars row (as a dict) back into a ZtfAlert or LsstAlert\n",
    "    instance.\n",
    "    \"\"\"\n",
    "    survey = row.get(\"survey\", \"\").lower()\n",
    "    cls = (\n",
    "        ZtfAlert\n",
    "        if survey == \"ztf\"\n",
    "        else LsstAlert\n",
    "        if survey == \"lsst\"\n",
    "        else None\n",
    "    )\n",
    "    if cls is None:\n",
    "        raise ValueError(f\"Unknown survey: {survey}\")\n",
    "    return cls.model_validate(row)\n",
    "\n",
    "\n",
    "# Create buttons and output area\n",
    "prev_button = widgets.Button(description=\"← Previous\")\n",
    "next_button = widgets.Button(description=\"Next →\")\n",
    "info_label = widgets.HTML()\n",
    "output = widgets.Output()\n",
    "\n",
    "# State\n",
    "current_idx = [0]\n",
    "\n",
    "\n",
    "def update_display():\n",
    "    if len(relevant_alerts) == 0:\n",
    "        info_label.value = \"No alerts found\"\n",
    "        return\n",
    "    idx = current_idx[0]\n",
    "    row = relevant_alerts.row(idx, named=True)\n",
    "    obs_date = row[\"obs_date\"]\n",
    "    alert = row_to_alert(row)\n",
    "    info_label.value = (\n",
    "        f\"<b>Alert {idx + 1} of {len(relevant_alerts)}</b>\"\n",
    "        f\" (observed {obs_date} by {alert.survey})\"\n",
    "    )\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        try:\n",
    "            alert.plot_cutouts()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not plot cutouts: {e}\")\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(alert.properties.model_dump_json(indent=2))\n",
    "\n",
    "\n",
    "def on_prev(b):\n",
    "    if current_idx[0] > 0:\n",
    "        current_idx[0] -= 1\n",
    "        update_display()\n",
    "\n",
    "\n",
    "def on_next(b):\n",
    "    if current_idx[0] < len(relevant_alerts) - 1:\n",
    "        current_idx[0] += 1\n",
    "        update_display()\n",
    "\n",
    "\n",
    "prev_button.on_click(on_prev)\n",
    "next_button.on_click(on_next)\n",
    "# Layout\n",
    "buttons = widgets.HBox([prev_button, next_button])\n",
    "container = widgets.VBox([info_label, buttons, output])\n",
    "display(container)\n",
    "update_display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babamul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
