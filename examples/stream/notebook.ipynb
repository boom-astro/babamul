{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Babamul streaming example\n",
    "\n",
    "In this notebook we'll read from Babamul streams to fetch alerts of interest\n",
    "and save them locally,\n",
    "e.g., to use in a machine learning pipeline.\n",
    "\n",
    "Before running, be sure to copy `.env.example` to `.env` and fill in\n",
    "your Babamul Kafka credentials from https://babamul.caltech.edu/profile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All imports\n",
    "import os\n",
    "from datetime import UTC, datetime\n",
    "from glob import glob\n",
    "\n",
    "import dotenv\n",
    "import duckdb\n",
    "import ipywidgets as widgets\n",
    "import polars as pl\n",
    "from IPython.display import display\n",
    "\n",
    "import babamul\n",
    "from babamul import LsstAlert, ZtfAlert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, load secrets from a local .env file if present\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Define some parameters\n",
    "limit = 1000\n",
    "group_id = \"example-group\"\n",
    "topics = [\"babamul.lsst.ztf-match.hosted\", \"babamul.ztf.lsst-match.hosted\"]\n",
    "topics = [\"^babamul.*\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Fetch new alerts from the streams\n",
    "\n",
    "Below we read from the stream and merge new alerts into our local cache\n",
    "in `data/alerts` so we can further process them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts = []\n",
    "\n",
    "with babamul.AlertConsumer(\n",
    "    topics=topics,\n",
    "    offset=\"latest\",\n",
    "    group_id=group_id,\n",
    "    timeout=10,\n",
    ") as consumer:\n",
    "    for n, alert in enumerate(consumer):\n",
    "        if n >= limit:\n",
    "            break\n",
    "        alerts.append(alert)\n",
    "\n",
    "# Create a Polars DataFrame of all alerts and merge them with the rest of our\n",
    "# local cache\n",
    "alerts_dir = \"data/alerts\"\n",
    "os.makedirs(alerts_dir, exist_ok=True)\n",
    "\n",
    "new_df = (\n",
    "    pl.DataFrame([alert.model_dump() for alert in alerts])\n",
    "    .unnest(\"candidate\", separator=\"_\")\n",
    "    .unnest(\"properties\", separator=\"_\")\n",
    "    .with_columns(\n",
    "        pl.col(\"candidate_jd\")\n",
    "        .map_elements(\n",
    "            lambda jd: datetime.fromtimestamp(\n",
    "                (jd - 2440587.5) * 86400, tz=UTC\n",
    "            ).date(),\n",
    "            return_dtype=pl.Date,\n",
    "        )\n",
    "        .alias(\"observation_date\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Merge with existing alerts cache\n",
    "parquet_glob = f\"{alerts_dir}/**/*.parquet\"\n",
    "parquet_files = glob(parquet_glob, recursive=True)\n",
    "if parquet_files:\n",
    "    existing = pl.scan_parquet(parquet_files).collect()\n",
    "    n_existing = len(existing)\n",
    "    df_combined = pl.concat([existing, new_df], how=\"vertical_relaxed\")\n",
    "else:\n",
    "    n_existing = 0\n",
    "    df_combined = new_df\n",
    "\n",
    "df_combined.write_parquet(alerts_dir, partition_by=\"observation_date\")\n",
    "print(\n",
    "    f\"Saved {len(df_combined)} alerts to {alerts_dir} \"\n",
    "    f\"({len(new_df)} new, {n_existing} existing)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## View alerts interactively\n",
    "\n",
    "The cell below allows us to page through the alerts of interest based on a\n",
    "SQL query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a SQL query to find candidates that are likely real astrophysical\n",
    "# transients\n",
    "sql = f\"\"\"\n",
    "    SELECT *\n",
    "    FROM read_parquet('{parquet_glob}')\n",
    "    WHERE\n",
    "        candidate_drb >= 0.8\n",
    "        AND (candidate_jd - COALESCE(candidate_jdstarthist, candidate_jd)) <= 30\n",
    "        AND (\n",
    "            candidate_ssdistnr IS NULL\n",
    "            OR candidate_ssdistnr >= 12\n",
    "            OR candidate_ssdistnr < 0\n",
    "        )\n",
    "        AND (properties_star IS NULL OR properties_star = FALSE)\n",
    "        AND (properties_near_brightstar IS NULL OR properties_near_brightstar = FALSE)\n",
    "        AND (candidate_isdiffpos IS NULL OR candidate_isdiffpos = TRUE)\n",
    "        AND properties_stationary = TRUE\n",
    "        AND observation_date > '2026-01-01'\n",
    "        ORDER BY observation_date DESC\n",
    "\"\"\"\n",
    "\n",
    "relevant_alerts = duckdb.sql(sql).pl()\n",
    "\n",
    "\n",
    "def row_to_alert(row: dict) -> ZtfAlert | LsstAlert:\n",
    "    \"\"\"Convert a Polars row (as a dict) back into a ZtfAlert or LsstAlert\n",
    "    instance.\n",
    "    \"\"\"\n",
    "    survey = row.get(\"survey\", \"\").lower()\n",
    "    cls = (\n",
    "        ZtfAlert\n",
    "        if survey == \"ztf\"\n",
    "        else LsstAlert\n",
    "        if survey == \"lsst\"\n",
    "        else None\n",
    "    )\n",
    "    if cls is None:\n",
    "        raise ValueError(f\"Unknown survey: {survey}\")\n",
    "    # Extract flattened candidate fields\n",
    "    candidate = {\n",
    "        k.removeprefix(\"candidate_\"): v\n",
    "        for k, v in row.items()\n",
    "        if k.startswith(\"candidate_\")\n",
    "    }\n",
    "    # Extract flattened properties fields\n",
    "    properties = {\n",
    "        k.removeprefix(\"properties_\"): v\n",
    "        for k, v in row.items()\n",
    "        if k.startswith(\"properties_\")\n",
    "    }\n",
    "    # Build alert dict with required and optional fields\n",
    "    alert_dict = {\n",
    "        \"candid\": row[\"candid\"],\n",
    "        \"objectId\": row[\"objectId\"],\n",
    "        \"candidate\": candidate,\n",
    "        \"properties\": properties,\n",
    "    }\n",
    "    # Add nested fields if they exist\n",
    "    nested_fields = [\n",
    "        \"prv_candidates\",\n",
    "        \"prv_nondetections\",\n",
    "        \"fp_hists\",\n",
    "        \"survey_matches\",\n",
    "    ]\n",
    "    for field in nested_fields:\n",
    "        if field in row and row[field] is not None:\n",
    "            alert_dict[field] = row[field]\n",
    "    # Add any remaining top-level fields (like cutouts, survey, etc.)\n",
    "    excluded_prefixes = (\"candidate_\", \"properties_\")\n",
    "    excluded_fields = {\"candid\", \"objectId\"} | set(nested_fields)\n",
    "    for key, value in row.items():\n",
    "        if (\n",
    "            not any(key.startswith(p) for p in excluded_prefixes)\n",
    "            and key not in excluded_fields\n",
    "        ) and value is not None:\n",
    "            alert_dict[key] = value\n",
    "\n",
    "    return cls.model_validate(alert_dict)\n",
    "\n",
    "\n",
    "# Create buttons and output area\n",
    "prev_button = widgets.Button(description=\"← Previous\")\n",
    "next_button = widgets.Button(description=\"Next →\")\n",
    "info_label = widgets.HTML()\n",
    "output = widgets.Output()\n",
    "\n",
    "# State\n",
    "current_idx = [0]\n",
    "\n",
    "\n",
    "def update_display():\n",
    "    if len(relevant_alerts) == 0:\n",
    "        info_label.value = \"No alerts found\"\n",
    "        return\n",
    "    idx = current_idx[0]\n",
    "    row = relevant_alerts.row(idx, named=True)\n",
    "    obs_date = row[\"observation_date\"]\n",
    "    alert = row_to_alert(row)\n",
    "    info_label.value = (\n",
    "        f\"<b>Alert {idx + 1} of {len(relevant_alerts)}</b>\"\n",
    "        f\" (observed {obs_date} by {alert.survey})\"\n",
    "    )\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        try:\n",
    "            alert.plot_cutouts()\n",
    "        except Exception as e:\n",
    "            print(f\"Could not plot cutouts: {e}\")\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(alert.properties.model_dump_json(indent=2))\n",
    "\n",
    "\n",
    "def on_prev(b):\n",
    "    if current_idx[0] > 0:\n",
    "        current_idx[0] -= 1\n",
    "        update_display()\n",
    "\n",
    "\n",
    "def on_next(b):\n",
    "    if current_idx[0] < len(relevant_alerts) - 1:\n",
    "        current_idx[0] += 1\n",
    "        update_display()\n",
    "\n",
    "\n",
    "prev_button.on_click(on_prev)\n",
    "next_button.on_click(on_next)\n",
    "# Layout\n",
    "buttons = widgets.HBox([prev_button, next_button])\n",
    "container = widgets.VBox([info_label, buttons, output])\n",
    "display(container)\n",
    "update_display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babamul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
