{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Babamul streaming example\n",
    "\n",
    "In this notebook we'll read from Babamul streams to fetch alerts of interest\n",
    "and display them interactively.\n",
    "\n",
    "ðŸš¨ **Before running, be sure to copy `.env.example` to `.env` and fill in\n",
    "your Babamul Kafka credentials from https://babamul.caltech.edu/profile.** ðŸš¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dotenv\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.table import Table\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import babamul\n",
    "from babamul import LsstAlert, ZtfAlert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "In this notebook, we'll listen to LSST alerts that are likely to be hosted (based on matches to the LSPSC catalog), and that match with a ZTF object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"babamul.lsst.ztf-match.hosted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, let's just grab one alert and inspect it\n",
    "# Note: initializing a consumer can take a few seconds, based on your distance\n",
    "#       from the Kafka cluster and the number of topics you subscribe to. Once\n",
    "# .      alerts start flowing, things get a lot faster!\n",
    "with babamul.AlertConsumer(\n",
    "    topics=topics,\n",
    "    offset=\"earliest\",\n",
    "    auto_commit=False,\n",
    "    timeout=15,\n",
    ") as consumer:\n",
    "    for alert in consumer:\n",
    "        alert.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Next, we define a pretty basic filtering function that will be applied to incoming alerts, to select\n",
    "a subset of them for display we might be interested in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_relevant(alert: ZtfAlert | LsstAlert):\n",
    "    if isinstance(alert, ZtfAlert):\n",
    "        age = alert.candidate.jd - alert.candidate.jdstarthist\n",
    "        # Only consider alerts for objects that were observed for the first time within the last 60 days, and more than 3 days old\n",
    "        if age < 3 or age > 60:\n",
    "            return False\n",
    "    if isinstance(alert, LsstAlert):\n",
    "        if alert.candidate.isDipole:\n",
    "            return False\n",
    "        if alert.candidate.psfFlux_flag:\n",
    "            return False\n",
    "        # Only consider alerts with a reasonable PSF fit (using a threshold on the reduced chi2 of the PSF fit)\n",
    "        if alert.candidate.psfChi2 / alert.candidate.psfNdata > 10.0:\n",
    "            return False\n",
    "        if alert.candidate.extendedness is None:\n",
    "            return False\n",
    "        if alert.candidate.shape_flag:\n",
    "            return False\n",
    "        if alert.candidate.centroid_flag:\n",
    "            return False\n",
    "\n",
    "    # Only consider alerts with a real-bogus score above 0.2\n",
    "    if alert.drb < 0.4:\n",
    "        return False\n",
    "\n",
    "    # Exclude alerts that are likely to be known SSOs\n",
    "    if alert.properties.rock:\n",
    "        return False\n",
    "\n",
    "    # Exclude alerts that are likely to be stars or near bright stars\n",
    "    if alert.properties.star:  # using PS1 PSC for ZTF, using LSPSC for LSST\n",
    "        return False\n",
    "\n",
    "    if alert.properties.near_brightstar:  # same here\n",
    "        return False\n",
    "\n",
    "    # Only consider positive subtractions (i.e. candidate is brighter than the reference)\n",
    "    if not alert.candidate.isdiffpos:\n",
    "        return False\n",
    "\n",
    "    # Exclude alerts that are not \"stationary\", i.e. not detected at least twice with sufficient time separation\n",
    "    # (helps rule out uncataloged asteroids, some boguses, ...)\n",
    "    return alert.properties.stationary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Let's run the filter on the the stream and selec up to `limit` alerts that match our criteria, and display them in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts = []\n",
    "limit = 2000  # we'll stop after we find 2000 relevant alerts, more than enough for our purposes here\n",
    "\n",
    "with babamul.AlertConsumer(\n",
    "    topics=topics,\n",
    "    offset=\"earliest\",\n",
    "    auto_commit=False,\n",
    "    timeout=15,\n",
    ") as consumer:\n",
    "    for alert in tqdm(consumer, desc=\"Filtering relevant alerts\"):\n",
    "        if is_relevant(alert):\n",
    "            alerts.append(alert)\n",
    "        if len(alerts) >= limit:\n",
    "            break\n",
    "\n",
    "print(f\"Fetched {len(alerts)} alerts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "Before we display the alerts, since we may have more than one alert per object,\n",
    "let's deduplicate the alerts by objectId, to make our life a little easier and\n",
    "avoid fetching data for the same object multiple times when we add cross-matches in the next step:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We deduplicate by objectId, keeping the most recent alert for each\n",
    "# scan for these alerts\n",
    "alerts_to_scan = {}\n",
    "for a in alerts:\n",
    "    if (\n",
    "        a.objectId not in alerts_to_scan\n",
    "        or a.candidate.jd > alerts_to_scan[a.objectId].candidate.jd\n",
    "    ):\n",
    "        alerts_to_scan[a.objectId] = a\n",
    "alerts_to_scan = list(alerts_to_scan.values())\n",
    "print(f\"After deduplication, {len(alerts_to_scan)} unique alerts remain.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Next, let's use the `add_cross_matches` helper function to fetch cross-match information \n",
    "(from the API) for our selected alerts, so we can use them to keep filtering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "babamul.add_cross_matches(alerts_to_scan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_revelant_using_crossmatches(alert: ZtfAlert | LsstAlert):\n",
    "    cross_matches: babamul.models.CrossMatches = alert.get_cross_matches()\n",
    "    if not cross_matches.ned or len(cross_matches.ned) == 0:\n",
    "        return False\n",
    "    if any(gal.distance_arcsec < 1.0 for gal in cross_matches.ned):\n",
    "        return False\n",
    "    if cross_matches.gaia and len(cross_matches.gaia) > 0:\n",
    "        return False\n",
    "    if cross_matches.lspsc and any(\n",
    "        m.score > 0.5\n",
    "        and (\n",
    "            m.distance_arcsec < 2.0\n",
    "            or (m.distance_arcsec < 30.0 and m.mag_white < 15.0)\n",
    "            or (m.distance_arcsec < 10.0 and m.mag_white < 16.0)\n",
    "            or (m.distance_arcsec < 5.0 and m.mag_white < 17.0)\n",
    "        )\n",
    "        for m in cross_matches.lspsc\n",
    "    ):\n",
    "        return False\n",
    "    return not (\n",
    "        cross_matches.milliquasar and len(cross_matches.milliquasar) > 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts_to_scan_filtered = []\n",
    "\n",
    "for alert in tqdm(alerts_to_scan):\n",
    "    if is_revelant_using_crossmatches(alert):\n",
    "        alerts_to_scan_filtered.append(alert)\n",
    "\n",
    "print(\n",
    "    f\"After excluding alerts using cross-matches with NED, Gaia, LSPSC, and MilliQuasar, {len(alerts_to_scan_filtered)} alerts remain that are likely not nuclear transients.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## View alerts interactively\n",
    "\n",
    "The cell below allows us to page through the alerts we have selected and view their contents interactively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "babamul.jupyter.scan_alerts(\n",
    "    sorted(\n",
    "        alerts_to_scan_filtered, key=lambda a: a.candidate.magpsf, reverse=True\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "Now maybe we can get a little more specific, and only look at alerts that have a nearby host in NED:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts = []\n",
    "limit = 100  # we'll stop after we find 2000 relevant alerts, more than enough for our purposes here\n",
    "\n",
    "with babamul.AlertConsumer(\n",
    "    topics=topics,\n",
    "    offset=\"earliest\",\n",
    "    auto_commit=False,\n",
    "    timeout=15,\n",
    ") as consumer:\n",
    "    for alert in tqdm(consumer, desc=\"Filtering relevant alerts\"):\n",
    "        if is_relevant(alert):\n",
    "            alerts.append(alert)\n",
    "        if len(alerts) == limit:\n",
    "            babamul.add_cross_matches(alerts)\n",
    "            alerts = [a for a in alerts if is_revelant_using_crossmatches(a)]\n",
    "        if len(alerts) >= limit:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_nearby_host(alert: ZtfAlert | LsstAlert):\n",
    "    # we use the API to retrieve the cross-matches for this alert's object\n",
    "    cross_matches: babamul.models.CrossMatches = alert.get_cross_matches()\n",
    "    # check if we have at least one match w/ NED\n",
    "    if not cross_matches.ned:\n",
    "        return False\n",
    "    # at least one of them should be at z <= 0.033 (~150 Mpc) and distance_kpc < 30\n",
    "    return any(\n",
    "        m.z is not None and m.z <= 0.033 and m.distance_kpc < 30\n",
    "        for m in cross_matches.ned\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 10\n",
    "nearby_alerts = []\n",
    "\n",
    "babamul.add_cross_matches(alerts_to_scan, n_threads=10)\n",
    "\n",
    "for a in tqdm(alerts, desc=\"Filtering nearby alerts\"):\n",
    "    if len(nearby_alerts) >= limit:\n",
    "        break\n",
    "    if has_nearby_host(a):\n",
    "        nearby_alerts.append(a)\n",
    "\n",
    "print(f\"Selected {len(nearby_alerts)} nearby alerts.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "babamul.jupyter.scan_alerts(nearby_alerts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's demonstrate using the API to look for alerts\n",
    "survey, object_id = nearby_alerts[0].survey, nearby_alerts[0].objectId\n",
    "obj = babamul.api.get_object(survey, object_id)\n",
    "obj.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = \"ZTF\"\n",
    "alerts_from_api = babamul.api.get_alerts(\n",
    "    survey,\n",
    "    start_jd=2460745.5,\n",
    "    end_jd=2460746.5,\n",
    "    is_rock=False,\n",
    "    is_star=False,\n",
    "    is_near_brightstar=False,\n",
    "    is_stationary=True,\n",
    "    min_drb=0.5,\n",
    ")\n",
    "\n",
    "print(f\"Found {len(alerts_from_api)} alerts matching initial criteria.\")\n",
    "\n",
    "alerts_filtered_from_api = []\n",
    "for a in tqdm(alerts_from_api, desc=\"Filtering relevant alerts\"):\n",
    "    if not is_relevant(a):\n",
    "        continue\n",
    "\n",
    "babamul.add_cross_matches(alerts_from_api, n_threads=10)\n",
    "nearby_alerts_from_api = []\n",
    "for a in tqdm(alerts_from_api, desc=\"Filtering nearby alerts\"):\n",
    "    if has_nearby_host(a):\n",
    "        nearby_alerts_from_api.append(a)\n",
    "\n",
    "print(\n",
    "    f\"Found {len(nearby_alerts_from_api)}/{len(alerts_from_api)} nearby alerts.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "babamul.jupyter.scan_alerts(nearby_alerts_from_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey = \"ZTF\"\n",
    "ra, dec = (\n",
    "    nearby_alerts_from_api[0].candidate.ra,\n",
    "    nearby_alerts_from_api[0].candidate.dec,\n",
    ")\n",
    "coordinates = SkyCoord(ra=ra, dec=dec, unit=\"deg\", frame=\"icrs\")\n",
    "radius_arcsec = 2.0\n",
    "conesearch_results = babamul.api.cone_search_alerts(\n",
    "    survey,\n",
    "    coordinates,\n",
    "    radius_arcsec,\n",
    "    is_rock=False,\n",
    "    is_star=False,\n",
    "    is_near_brightstar=False,\n",
    "    is_stationary=True,\n",
    "    min_drb=0.5,\n",
    ")\n",
    "\n",
    "for pos_name, alerts in conesearch_results.items():\n",
    "    print(f\"Found {len(alerts)} alerts for position {pos_name}.\")\n",
    "    for a in alerts:\n",
    "        a.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load the NED LVS catalog at .data/NEDLVS_20250602.fits\n",
    "# you can download it from https://ned.ipac.caltech.edu/NED::LVS/\n",
    "ned_lvs: Table = Table.read(\"data/NEDLVS_20250602.fits\")\n",
    "print(f\"Loaded NED LVS catalog with {len(ned_lvs):,} entries.\")\n",
    "# let's keep the nearby galaxies with z <= 0.03 (~150 Mpc)\n",
    "nearby_galaxies = ned_lvs[ned_lvs[\"z\"] <= 0.03]\n",
    "print(f\"Found {len(nearby_galaxies):,} nearby galaxies at less than 150 Mpc.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "survey, radius_arcsec = \"LSST\", 60.0\n",
    "conesearch_results: dict[str, ZtfAlert | LsstAlert] = (\n",
    "    babamul.api.cone_search_alerts(\n",
    "        survey,\n",
    "        nearby_galaxies,\n",
    "        radius_arcsec=radius_arcsec,\n",
    "        is_rock=False,\n",
    "        is_star=False,\n",
    "        is_near_brightstar=False,\n",
    "        is_stationary=True,\n",
    "        min_drb=0.8,\n",
    "        n_threads=8,\n",
    "        batch_size=500,\n",
    "    )\n",
    ")\n",
    "\n",
    "galaxies_with_alerts = [\n",
    "    name for name, alerts in conesearch_results.items() if alerts\n",
    "]\n",
    "print(\n",
    "    f\"Found {len(galaxies_with_alerts)} nearby galaxies with alerts within {radius_arcsec} arcseconds.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "From here on out, the notebook deserved some refactoring to use the latest from the API, but I haven't gotten around to it yet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosted_alerts: dict[str, list[ZtfAlert | LsstAlert]] = {}\n",
    "for alerts in conesearch_results.values():\n",
    "    for a in alerts:\n",
    "        a: LsstAlert\n",
    "        if not a.candidate.isdiffpos:\n",
    "            continue\n",
    "        if a.candidate.isDipole:\n",
    "            continue\n",
    "        if a.candidate.magpsf > 21.5:\n",
    "            continue\n",
    "        if a.candidate.psfFlux_flag:\n",
    "            continue\n",
    "        a.get_cross_matches()\n",
    "        if a.cross_matches.milliquasar:\n",
    "            continue\n",
    "        photometry = a.get_photometry()\n",
    "        # keep those that are < 60 days old\n",
    "        # and with an amplitude > 1 mag\n",
    "        first_jd = a.candidate.jd\n",
    "        faintest_mag, brightest_mag = a.candidate.magpsf, a.candidate.magpsf\n",
    "        for p in photometry:\n",
    "            if p.isdiffpos and p.magpsf:\n",
    "                if p.jd < first_jd:\n",
    "                    first_jd = p.jd\n",
    "                if p.magpsf > faintest_mag:\n",
    "                    faintest_mag = p.magpsf\n",
    "                if p.magpsf < brightest_mag:\n",
    "                    brightest_mag = p.magpsf\n",
    "        age = a.candidate.jd - first_jd if first_jd else None\n",
    "        amplitude = (\n",
    "            faintest_mag - brightest_mag\n",
    "            if faintest_mag and brightest_mag\n",
    "            else None\n",
    "        )\n",
    "        if age is None or age > 60 or age < 10:\n",
    "            continue\n",
    "        if amplitude is None or amplitude < 1:\n",
    "            continue\n",
    "        # if not is_relevant_complex(a):\n",
    "        #     continue\n",
    "        if (\n",
    "            a.objectId not in hosted_alerts\n",
    "            or a.candidate.jd > hosted_alerts[a.objectId].candidate.jd\n",
    "        ):\n",
    "            hosted_alerts[a.objectId] = a\n",
    "hosted_alerts = list(hosted_alerts.values())\n",
    "\n",
    "print(\n",
    "    f\"Found {len(hosted_alerts)} unique hosted alerts around nearby galaxies.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "babamul.jupyter.scan_alerts(hosted_alerts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's load data/tns_public_objects.csv, which is a dump of all public objects in the Transient Name Server as of 2026-02-12\n",
    "tns_objects: Table = Table.read(\"data/tns_public_objects.csv\")\n",
    "print(f\"Loaded TNS public objects catalog with {len(tns_objects):,} entries.\")\n",
    "\n",
    "# let's remove those with type AGN\n",
    "tns_objects = tns_objects[tns_objects[\"type\"] != \"AGN\"]\n",
    "# let's remove the already classified supernovae\n",
    "tns_objects = tns_objects[tns_objects[\"name_prefix\"] != \"SN\"]\n",
    "print(\n",
    "    f\"Filtered TNS objects to {len(tns_objects):,} entries after removing AGN.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do a cone search against the alerts for the tns_sne\n",
    "survey, radius_arcsec = \"LSST\", 1.5\n",
    "conesearch_results = babamul.api.cone_search_alerts(\n",
    "    survey,\n",
    "    tns_objects,\n",
    "    radius_arcsec=radius_arcsec,\n",
    "    n_threads=8,\n",
    "    batch_size=500,\n",
    ")\n",
    "\n",
    "tns_sne_candidates = [\n",
    "    name for name, alerts in conesearch_results.items() if alerts\n",
    "]\n",
    "print(\n",
    "    f\"Found {len(tns_sne_candidates)} TNS supernovae with alerts within {radius_arcsec} arcseconds:\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scan for these alerts\n",
    "alerts_to_scan = {}\n",
    "for _, alerts in conesearch_results.items():\n",
    "    for a in alerts:\n",
    "        if (\n",
    "            a.objectId not in alerts_to_scan\n",
    "            or a.candidate.jd > alerts_to_scan[a.objectId].candidate.jd\n",
    "        ):\n",
    "            alerts_to_scan[a.objectId] = a\n",
    "print(f\"Found {len(alerts_to_scan)} unique alerts around TNS supernovae.\")\n",
    "\n",
    "babamul.jupyter.scan_alerts(list(alerts_to_scan.values()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babamul (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
